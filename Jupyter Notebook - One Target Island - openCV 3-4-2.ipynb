{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One target island (openCV 3.4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "\n",
    "Make sure that Python 3 and the following modules (recommended version ID) are installed on your computer before running this cell:\n",
    "\n",
    "numpy (1.18.1),\n",
    "sounddevice (0.3.14),\n",
    "openCV (3.4.2),\n",
    "tkinter (8.6.8),\n",
    "xlxswriter (1.2.7),\n",
    "scipy (1.3.2),\n",
    "pyfirmata (1.1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                        # Import numpy module\n",
    "                                          # conda install -c conda-forge python-sounddevice\n",
    "import sounddevice as sd                  # Import sounddevice module for \"real-time\" sound playback\n",
    "import cv2                                # Import opencv module for image processing\n",
    "print(cv2.__version__)                    # Make sure you have the correct version of openCV \n",
    "import tkinter as tk                      # Import Tkinter module for GUIs\n",
    "import xlsxwriter                         # Import xlsxwriter module for writing a protocol on-the-fly\n",
    "\n",
    "from scipy.io  import wavfile             # WAV-file import filter\n",
    "from pyfirmata import Arduino             # Arduino support\n",
    "from math      import e                   # Euler's number\n",
    "\n",
    "import math                               # Import math module\n",
    "import time                               # Import time module for time measurements and pausing\n",
    "import random                             # Import random module for random number generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that defines global variables based on user inputs at a starting screen (below)\n",
    "def show_entry_fields():\n",
    "    \n",
    "    print('Trials per Session: %s' % e1.get())\n",
    "    print('Session Duration: %s' % e2.get())\n",
    "    print('Trial Duration: %s' % e3.get())\n",
    "    print('Radius of the Starting Platform: %s' % e4.get())\n",
    "    print('X-Coordinate of the Starting Platform: %s' % e5.get())\n",
    "    print('Y-Coordinate of the Starting Platform: %s' % e6.get())\n",
    "    print('Radius of the target platform: %s' % e7.get())\n",
    "    print('Target duration: %s' % e8.get())\n",
    "    print('Subject and Date: %s' % e9.get())\n",
    "    print('Subject is darker than background: %s' % e10.get())\n",
    "    print('Initialization Duration: %s' % e11.get())\n",
    "    \n",
    "    global trialNumber \n",
    "    trialNumber = int(e1.get())\n",
    "    global sessionDuration \n",
    "    sessionDuration = int(e2.get())\n",
    "    global trialDuration \n",
    "    trialDuration = int(e3.get())\n",
    "    global startRadius\n",
    "    startRadius = int(e4.get())\n",
    "    global startX\n",
    "    startX = int(e5.get())\n",
    "    global startY\n",
    "    startY = int(e6.get())\n",
    "    global targetRadius\n",
    "    targetRadius = int(e7.get())\n",
    "    global targetDuration\n",
    "    targetDuration = float(e8.get())\n",
    "    global experimentID\n",
    "    experimentID = e9.get()\n",
    "    global backgroundColor\n",
    "    backgroundColor = e10.get()\n",
    "    global initDuration\n",
    "    initDuration = float(e11.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the arena dimensions\n",
    "\n",
    "Here, the arena position and dimensions can be defined. In the example setup, a circular arena of 80 cm radius is filmed by a USB-webcam with a resolution of 800*600 px. In the cell below, the arena dimensions optimally use the resolution of the webcam in terms of spatial resolution of the later tracking. You may have to redefine the values in the next cell to fit your combination of camera resolution and arena dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arena coordinates and radius (best set to maximum spatial resolution at given image size)\n",
    "# Here: Video resolution = 800*600\n",
    "arenaX      = 400\n",
    "arenaY      = 300\n",
    "arenaRadius = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a starting screen\n",
    "\n",
    "The next cell will open a window that can be used to configure the experiment by entering the desired number of trials per session (usually limited by the number of rewards the feeder provides without refil), the session and trial durations, the size (here: 134 px in diameter = 17.87 cm) and the XY-position of the starting platform, the size of the target area, and the duration the animal has to spend in the target to recieve a reward. In addition, you can give your experiment a purposeful ID (e.g. subject ID, experiment type and date), provide information about the contrast between arena and subject, and define the duration the animal has to spend in the starting area to initialize a new trial. \n",
    "\n",
    "If you choose your target size, always make sure that it is small enough to fit in the arena without overlap with the starting/initialization area. \n",
    "\n",
    "The experiment ID you enter in the popup window will automatically be added to the file names of the protocols that will be generated for each session.\n",
    "\n",
    "**To save your configuration, hit the apply button**. To close the popup window and proceed, hit the continue button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials per Session: 50\n",
      "Session Duration: 3600\n",
      "Trial Duration: 60\n",
      "Radius of the Starting Platform: 67\n",
      "X-Coordinate of the Starting Platform: 195\n",
      "Y-Coordinate of the Starting Platform: 195\n",
      "Radius of the target platform: 80\n",
      "Target duration: 5\n",
      "Subject and Date: SubjectID_ExpType_MM_DD_20YY\n",
      "Subject is darker than background: T\n",
      "Initialization Duration: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Starting screen\n",
    "master = tk.Tk()\n",
    "master.title('Experimental parameters')\n",
    "tk.Label(master, text=\"Instructions: \\n 1. Enter parameters (only integers are allowed as numbers) \\n 2. Press 'Apply' \\n 3. Press 'Continue'\").grid(row=0, padx=10, pady=10)\n",
    "tk.Label(master, text=\"Trials per session\").grid(row=4, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Session duration [s]\").grid(row=5, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Trial duration [s]\").grid(row=6, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Radius of the starting platform [pixels]\").grid(row=7, padx=5, pady=5)\n",
    "tk.Label(master, text=\"X-position of the starting platform [pixels]\").grid(row=8, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Y-position of the starting platform [pixels]\").grid(row=9, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Radius of the target platform [pixels]\").grid(row=10, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Target duration [s]\").grid(row=11, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Experiment ID [subject_date]\").grid(row=12, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Subject is darker than background [T = True; F = False]\").grid(row=13, padx=5, pady=5)\n",
    "tk.Label(master, text=\"Initialisation Duration [s]\").grid(row=14, padx=5, pady=5)\n",
    "\n",
    "e1 = tk.Entry(master)\n",
    "e1.insert('end', '50')\n",
    "e2 = tk.Entry(master)\n",
    "e2.insert('end', '3600')\n",
    "e3 = tk.Entry(master)\n",
    "e3.insert('end', '60')\n",
    "e4 = tk.Entry(master)\n",
    "e4.insert('end', '67')\n",
    "e5 = tk.Entry(master)\n",
    "e5.insert('end', '195')\n",
    "e6 = tk.Entry(master)\n",
    "e6.insert('end', '195')\n",
    "e7 = tk.Entry(master)\n",
    "e7.insert('end', '80')\n",
    "e8 = tk.Entry(master)\n",
    "e8.insert('end', '5')\n",
    "e9 = tk.Entry(master)\n",
    "e9.insert('end', 'SubjectID_ExpType_MM_DD_20YY')\n",
    "e10 = tk.Entry(master)\n",
    "e10.insert('end', 'T')\n",
    "e11 = tk.Entry(master)\n",
    "e11.insert('end', '0.2')\n",
    "\n",
    "e1.grid(row=4, column=1)\n",
    "e2.grid(row=5, column=1)\n",
    "e3.grid(row=6, column=1)\n",
    "e4.grid(row=7, column=1)\n",
    "e5.grid(row=8, column=1)\n",
    "e6.grid(row=9, column=1)\n",
    "e7.grid(row=10, column=1)\n",
    "e8.grid(row=11, column=1)\n",
    "e9.grid(row=12, column=1)\n",
    "e10.grid(row=13, column=1)\n",
    "e11.grid(row=14, column=1)\n",
    "\n",
    "tk.Button(master, text='Apply', command=show_entry_fields).grid(row=15, column=0, sticky='s', pady=4)\n",
    "tk.Button(master, text='Continue', command=master.destroy).grid(row=15, column=1, sticky='w', pady=4)\n",
    "\n",
    "tk.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol 1\n",
    "\n",
    "Run the upcoming cell, if you want to save the chosen experimetal parameters to a txt-file (\"ExperimentID_parameters.txt\"). The file will be saved to the folder containing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves all parameters to a txt-file with the user-defined \"Experiment ID\" as filename\n",
    "parametersName = experimentID + '_parameters.txt'\n",
    "with open(parametersName, 'w') as f:\n",
    "    print(time.asctime(time.localtime(time.time())), file=f)\n",
    "    print('Trials per Session: %s' % trialNumber, file=f)\n",
    "    print('Session Duration: %s' % sessionDuration, file=f)\n",
    "    print('Trial Duration: %s' % trialDuration, file=f)\n",
    "    print('Radius of the Starting Platform: %s' % startRadius, file=f)\n",
    "    print('X-Coordinate of the Starting Platform: %s' % startX, file=f)\n",
    "    print('Y-Coordinate of the Starting Platform: %s' % startY, file=f)\n",
    "    print('Radius of the target platform: %s' % targetRadius, file=f)\n",
    "    print('Duration the subject has to stay in the target area: %s' % targetDuration, file=f)\n",
    "    print('Subject and Date: %s' % experimentID, file=f)\n",
    "    print('Subject is darker than background: %s' % backgroundColor, file=f)\n",
    "    print('Initialization Duration: %s' % initDuration, file=f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the microcontroller\n",
    "\n",
    "The next cell Initializes a microcontroller for subsequent hardware control. This is, where you will probably have to get creative yourself, depending on what you would like to do. Here, we use an Arduino Nano. With the channel definitions below, we can later provide differently colored illumination during the experiment (for example to stimulate with colors rather than sound) and trigger two different feeders. \n",
    "\n",
    "For the example setup, two automatic fish feeders with 27 feeding slots each were \"hacked\", so that they can be controlled *via* two additional Arduinos with motor shields. These additional Arduinos drive the feeder motors each time they get a trigger signal from the main Arduino. The two feeders allow the provision of 54 rewards per session. The two feeders were installed at different positions above the arena and are activated alternately, to lower the predictability of where in the arena the reward will drop. The starting feeder is chosen randomly for each new session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors and feeder channel for Arduino output\n",
    "arduinoBlue = 9         # Blue diodes\n",
    "arduinoYellow = 10      # Yellow diodes\n",
    "arduinoRed = 11         # Red diodes\n",
    "arduinoFeeder1 = 12     # Trigger pulse for feeder1\n",
    "arduinoFeeder2 = 4      # Trigger pulse for feeder2\n",
    "\n",
    "# Feeder changes every trial, start feeder randomized\n",
    "feederID = random.randrange(1,3,1)\n",
    "\n",
    "# Initialize Arduino\n",
    "board = Arduino('COM3')    # May be another COM-Port - in Windows, just check the Hardware Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the audio stream\n",
    "\n",
    "The following cell initiates the audio stream, to which we will later feed our stimuli. The default sample rate is set to 44.1 kHz. The cell also loads sound files with the stimuli. Here, we use short pure tones as stimuli and a silent sound object, which is fed to the audiostream between stimuli. In our setup, we found this to be necessarry to reduce undesired clicking sounds at stimulus on- and offset, even though the sounds are ramped. Whether this will be necessary for you, will strongly depend on your audio hardware. \n",
    "\n",
    "The audio stimulation provided by this notebook differs from the MATLAB version in two important aspects: Firstly, the MATLAB version generates the stimuli on the fly, while this notebook uses sound files as input. Feel free to change the code if you prefer the other solution. Secondly, the MATLAB version stimulates at fixed time intervals and the sample rate of the video tracking is locked to the stimulation interval, i.e. high temporal precision in the sound stimulation comes with the cost of lower temporal resolution of the animal tracking. Here, we chose the opposite approach, with the video feed defining the cycle frequency (approx. 14 Hz with the given Camera and a resolution of 800x600 px) and the audio stimulation being locked to the framerate of the camera. Thus, higher temporal resolution of the animal tracking comes with the cost that inter-stimulus intervals cannot freely be chosen, but only be multiple integers (3 or higher) of the mean video frame duration. In the example setup and the code below, we decided for the stimulus to be played every three cycles (approx. every 215 ms). \n",
    "\n",
    "The duration of the audio files should not exceed the cycle length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1969cbc2e2a8>:13: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  distractorSoundTrial = wavfile.read('./10kHz-short-68.wav')[1]\n",
      "<ipython-input-11-1969cbc2e2a8>:14: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  attractorSoundTarget1 = wavfile.read('./4000Hz-short-68.wav')[1]\n",
      "<ipython-input-11-1969cbc2e2a8>:15: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  silenceSound = wavfile.read('./silence-short-68.wav')[1]\n"
     ]
    }
   ],
   "source": [
    "# Set sample rate for audio output\n",
    "sd.default.samplerate = 44100\n",
    "fs = 44100          \n",
    "\n",
    "# Audio stream\n",
    "stream = sd.OutputStream(samplerate=fs, channels=1, dtype='float32')\n",
    "\n",
    "# Cycle counter: sound is played every \"delayLength\" cycles\n",
    "commonCycle = 1\n",
    "delayLength = 3  \n",
    "\n",
    "# Open sound files\n",
    "distractorSoundTrial = wavfile.read('./10kHz-short-68.wav')[1]\n",
    "attractorSoundTarget1 = wavfile.read('./4000Hz-short-68.wav')[1]\n",
    "silenceSound = wavfile.read('./silence-short-68.wav')[1]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silenceSound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol 2\n",
    "\n",
    "The following cell generates a video object to which the later video feed will be saved. The colours that are defined will later be used for labeling. The labelled video file (\"ExperimentID_video.avi\") will be saved to the folder containing this notebook for documentation purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BGR colors\n",
    "BGR_COLOR = {'red': (0,0,255),\n",
    "             'green': (127,255,0),\n",
    "             'blue': (255,127,0),\n",
    "             'yellow': (0,127,255),\n",
    "             'black': (0,0,0),\n",
    "             'white': (255,255,255)}\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "videoName = experimentID + '_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# Make sure that the frame rate of your output appoximately matches \n",
    "# the number of cycles per second, to avoid time lapsed output videos\n",
    "out = cv2.VideoWriter(videoName,fourcc, 15.0, (800,600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture a background image\n",
    "\n",
    "The tracking algorithm used in this notebook compares the frames of the video feed during the experiment with an image of the empty arena to later track the position of the largest object in the arena (which usually is your animal). If you are confident in the stability of your video quality, it should suffice to capture the picture once and to skip this cell in the subsequent experiments. However, since this step only takes a few seconds, we recommend to take a new picture of the arena for each new experiment. In the preview of the video feed that will pop-up if you run the next cell, the space outside the arena is masked, so that the camera preview can also be used to check if the camera/arena are still positioned correctly. \n",
    "\n",
    "Before taking the picture, make sure that the conditions in your lab (especially the illumination) are the exact same as they will be during the experiments. Once you are happy with the preview of your background image, press \"c\" to capture the image. It will be saved as \"Background.png\" to the folder containing this notebook.\n",
    "\n",
    "This notebook will use the main camera of your system as an input device. If you have more than one camera installed (e.g. on a notebook with internal chat camera), make sure to deactivate all cameras other than the camera of your setup  prior to running the notebook. Also make sure that the video dimensions defined here match you arena dimensions defined above and the video dimensions of the video feeds that will be defined in the subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define video capture device (0 = webcam1) to capture background frame\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set picture dimensions\n",
    "cap.set(3,800)      # Width\n",
    "cap.set(4,600)      # Height\n",
    "\n",
    "# Capture Background frame (c = capture)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, img = cap.read()\n",
    "    img2 = img\n",
    "\n",
    "    # Display the resulting frame\n",
    "    imgArena = cv2.circle(img,(arenaX,arenaY), arenaRadius, (0,0,255), 2)\n",
    "    imgArenaStart = cv2.circle(imgArena,(startX,startY), startRadius, (255,0,255), 2)\n",
    "\n",
    "    # Mask the space outside the arena\n",
    "    mask = np.zeros(shape = img.shape, dtype = \"uint8\")\n",
    "    cv2.circle(mask, (arenaX,arenaY), arenaRadius, (255,255,255), -1)\n",
    "\n",
    "    maskedImg2 = cv2.bitwise_and(src1 = img2, src2 = mask)\n",
    "    imgArenaStart = cv2.bitwise_and(src1 = imgArenaStart, src2 = mask)\n",
    "\n",
    "    cv2.imshow('Press (c)-to capture the background image',imgArenaStart)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        cv2.imwrite('Background.png',maskedImg2)\n",
    "        break\n",
    "\n",
    "# When the background image is captured, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Loads current background as object img for later use\n",
    "img = cv2.imread('Background.png',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the experiment\n",
    "\n",
    "The following cell will provide another preview of the video feed from the arena. It will allow you to double-check if everything is prepared for the experiment. If so, you can bring your animal and put it into the arena. \n",
    "\n",
    "Once you have left the room with your setup and are happy with what you see in the live-feed, hit \"c\" to close the preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define video capture device for live-stream (0 = webcam1)\n",
    "cap2 = cv2.VideoCapture(0)\n",
    "# Set picture dimensions\n",
    "cap2.set(3,800)\n",
    "cap2.set(4,600)\n",
    "\n",
    "# Show video to see animal leaving the box\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, img3 = cap2.read()\n",
    "    \n",
    "    cv2.imshow('Press (c)-to continue',img3)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        break\n",
    "\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the camera\n",
    "\n",
    "This cell initializes the camera for the actual tracking and defines some counters and dummy variables needed during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define video capture device for live-stream (0 = webcam1) and tracking\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set picture dimensions\n",
    "cap.set(3,800)\n",
    "cap.set(4,600)\n",
    "\n",
    "# Mask the space outside the arena\n",
    "mask = np.zeros(shape = img.shape, dtype = \"uint8\")\n",
    "cv2.circle(mask, (arenaX,arenaY), arenaRadius, (255,255,255), -1)\n",
    "\n",
    "# Experiment starts in phase 0 with 0 trials\n",
    "expPhase = 0   \n",
    "trialCounter = 0\n",
    "rewardCounter = 0\n",
    "frameCounter = 0\n",
    "trialCountdown = 0\n",
    "targetCountdown = 0\n",
    "\n",
    "# Dummy values for target area generation (up to 5)\n",
    "randomX = 9000     \n",
    "randomY = 9000     \n",
    "random2X = 9000     \n",
    "random2Y = 9000     \n",
    "random3X = 9000     \n",
    "random3Y = 9000     \n",
    "random4X = 9000     \n",
    "random4Y = 9000     \n",
    "random5X = 9000     \n",
    "random5Y = 9000     \n",
    "targetX = 9999\n",
    "targetY = 9999\n",
    "target2X = 9999\n",
    "target2Y = 9999\n",
    "target3X = 9999\n",
    "target3Y = 9999\n",
    "target4X = 9999\n",
    "target4Y = 9999\n",
    "target5X = 9999\n",
    "target5Y = 9999\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol 3\n",
    "\n",
    "The following cell generates an Excel-file to which the essential data (i.e. animal position, positions of the target areas, etc.) from each cycle (video frame) of the experiment will be saved. The Excel-file (\"ExperimentID_protocol.xlsx\") will be saved to the folder containing this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Excel workbook and worksheet\n",
    "protocolName  = experimentID + '_protocol.xlsx'\n",
    "workbook = xlsxwriter.Workbook(protocolName, {'constant_memory': True, 'tmpdir': './'})\n",
    "\n",
    "# Workbook = xlsxwriter.Workbook(protocolName)\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# First row of the Excel sheet with column headings\n",
    "protocolRow = (\n",
    "        ['FrameID', 'Time [s]', 'Phase', 'Animal_x', 'Animal_y', 'Start_x', 'Start_y', 'Start_rad', 'Target_x', 'Target_y', 'Target_rad', 'TrialID', 'Rewarded Trials [%]', 'Sound Played', 'Common cycle ID', 'Odd1_x', 'Odd1_Y', 'Odd2_x', 'Odd2_Y', 'Odd3_x', 'Odd3_Y', 'Odd4_x', 'Odd4_Y'],\n",
    "        )\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "# Provides column headings for the protocol\n",
    "for frame, timeStamp, phase, anX, anY, stX, stY, stRad, tarX, tarY, tarRad, trial, rewP, soundP, comCy, odd1X, odd1Y, odd2X, odd2Y, odd3X, odd3Y, odd4X, odd4Y in (protocolRow):\n",
    "    worksheet.write(row, col,     frame)        # Frame ID\n",
    "    worksheet.write(row, col + 1, timeStamp)    # Time stamp\n",
    "    worksheet.write(row, col + 2, phase)        # Phase of experiment\n",
    "    worksheet.write(row, col + 3, anX)          # X-Coordinate of the subject\n",
    "    worksheet.write(row, col + 4, anY)          # Y-Coordinate of the subject\n",
    "    worksheet.write(row, col + 5, stX)          # X-Coordinate of the starting platform\n",
    "    worksheet.write(row, col + 6, stY)          # Y-Coordinate of the starting platform\n",
    "    worksheet.write(row, col + 7, stRad)        # Radius of the starting platform\n",
    "    worksheet.write(row, col + 8, tarX)         # X-Coordinate of the target \n",
    "    worksheet.write(row, col + 9, tarY)         # Y-Coordinate of the target \n",
    "    worksheet.write(row, col + 10, tarRad)      # Radius of the target platform\n",
    "    worksheet.write(row, col + 11, trial)       # Trial ID\n",
    "    worksheet.write(row, col + 12, rewP)        # Percentage of trials rewarded\n",
    "    worksheet.write(row, col + 13, soundP)      # sound played\n",
    "    worksheet.write(row, col + 14, comCy)       # common cycle ID\n",
    "    worksheet.write(row, col + 15, odd1X)       # X-Coordinate of the odd1 target \n",
    "    worksheet.write(row, col + 16, odd1Y)       # Y-Coordinate of the odd1 target \n",
    "    worksheet.write(row, col + 17, odd2X)       # X-Coordinate of the odd2 target \n",
    "    worksheet.write(row, col + 18, odd2Y)       # Y-Coordinate of the odd2 target \n",
    "    worksheet.write(row, col + 19, odd3X)       # X-Coordinate of the odd3 target \n",
    "    worksheet.write(row, col + 20, odd3Y)       # Y-Coordinate of the odd3 target \n",
    "    worksheet.write(row, col + 21, odd4X)       # X-Coordinate of the odd4 target \n",
    "    worksheet.write(row, col + 22, odd4Y)       # Y-Coordinate of the odd4 target \n",
    "    row += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a start button\n",
    "\n",
    "This cell provides a start button. If you run this notebook cell-by-cell, this button is obsolete. However, if you run all cells at once, this is the point of no return. Once you have started the experiment, it cannot be paused until the session criteria are met or it is interrupted manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "frame = tk.Frame(root)\n",
    "frame.pack()\n",
    "button = tk.Button(frame, \n",
    "                   text=\"Start Experiment!\", \n",
    "                   fg=\"black\",\n",
    "                   command=root.destroy)\n",
    "button.pack(side=tk.LEFT)\n",
    "#def abs():\n",
    "#    root.destroy\n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the experiment\n",
    "\n",
    "The final cell contains all the code for animal tracking and hardware control in response to the animals's behavior. We hope that the comments provided in the code suffice to understand the individual steps and to adjust them to your own setup and needs, if necessary.\n",
    "\n",
    "The experiment will stop automatically, if either one of the following conditions is met:\n",
    "\n",
    "(1) The pre-defined session duration is reached; <br/>\n",
    "(2) The pre-definde number of trials is reached; <br/>\n",
    "(3) The experiment is voluntarily stopped prematurely by hitting \"q\". \n",
    "\n",
    "If you should decide to stop the experiment manually, always use the \"q\"-button on your keyboard. Just quitting Jupyter/Python will lead to data loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and start the experiment timer\n",
    "expTime = time.time()\n",
    "\n",
    "# Start the audio stream\n",
    "stream.start()\n",
    "\n",
    "# Conditions to be met for the experiment to start and continue\n",
    "while(cap.isOpened() and trialCounter<trialNumber and (time.time()-expTime)<=sessionDuration):\n",
    "    \n",
    "    # Here you can choose different modes of amplitude modulation by commenting/uncommenting \n",
    "    ampMod = (random.randrange(2396,2962,1)/100)**e/10000 # Unbiased Voltage Ratio -5dB\n",
    "    ### ampMod = random.randrange(5623,10001,1)/10000 # Voltage Ratio -5dB\n",
    "    ### ampMod = random.randrange(3162,10001,1)/10000 # Power Ratio -5dB\n",
    "    ### ampMod = 1 # No modulation\n",
    "    \n",
    "    # Phase 0 = Animal just entered the arena or finished a trial\n",
    "    if expPhase == 0:\n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret==True:\n",
    "\n",
    "            maskedFrame = cv2.bitwise_and(src1 = frame, src2 = mask)\n",
    "            \n",
    "            # In phase 0, there is no acoustic stimulation, so this is \n",
    "            # kept at 1 for all cycles spent in expPhase 0\n",
    "            commonCycle = 1\n",
    "            \n",
    "            # Animal tracking\n",
    "            # Substracts background from current frame\n",
    "            if backgroundColor == 'T':\n",
    "                subject = cv2.subtract(img,maskedFrame)\n",
    "            else:\n",
    "                subject = cv2.subtract(maskedFrame,img)\n",
    "    \n",
    "            # Converts subject to grey scale\n",
    "            subjectGray = cv2.cvtColor(subject, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Applies blur and thresholding to the subject\n",
    "            kernelSize = (25,25)\n",
    "            frameBlur = cv2.GaussianBlur(subjectGray, kernelSize, 0)\n",
    "            _, thresh = cv2.threshold(frameBlur, 40, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            \n",
    "            # Finds contours and selects the contour with the largest area\n",
    "            ###contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            _, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            \n",
    "            # If there is no subject, the sreen is blackened, indicating that there is a problem\n",
    "            # with the tracking or that your animal has escaped.\n",
    "            # This code block helps when building and testing the setup. During a real experiment,\n",
    "            # the condition hopefully is never met. \n",
    "            if (len(contours) == 0): \n",
    "                x = 20\n",
    "                y = 40\n",
    "                subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "            \n",
    "            # If there is a subject, it is tracked\n",
    "            else:\n",
    "                contour = contours[np.argmax(list(map(cv2.contourArea, contours)))]\n",
    "                M = cv2.moments(contour)\n",
    "                if ((M['m00']) == 0):\n",
    "                    x = 20\n",
    "                    y = 40\n",
    "                    subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                    subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "                else:\n",
    "                    x = int(M['m10'] / M['m00'])\n",
    "                    y = int(M['m01'] / M['m00'])\n",
    "                    hull = cv2.convexHull(contour)\n",
    "                    subjectHullCentroid = maskedFrame\n",
    "          \n",
    "                # Draws contour and centroid of the subject\n",
    "                cv2.drawContours(subjectHullCentroid, [contour], 0, BGR_COLOR['green'], 1, cv2.LINE_AA)\n",
    "                subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "            \n",
    "            # Draws the arena contour, the starting platform, and a red dot, signalling that the subject is outside the starting area\n",
    "            subjectHullCentroidArena = cv2.circle(subjectHullCentroid,(arenaX,arenaY), arenaRadius, (0,0,255), 2)\n",
    "            subjectHullCentroidArenaStart = cv2.circle(subjectHullCentroidArena,(startX,startY), startRadius, (255,0,255), 2)\n",
    "            subjectHullCentroidArenaStartOut = cv2.circle(subjectHullCentroidArena,(20,20), 10, BGR_COLOR['red'], -6)\n",
    " \n",
    "            # Adds a stopwatch for the experiment duration to the video\n",
    "            subjectHullCentroidArenaStartOutText=cv2.putText(subjectHullCentroidArenaStartOut,\n",
    "            '' + str('Time: %.2f' % ((time.time()-expTime))),\n",
    "            (10,590), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['white'])\n",
    "            \n",
    "            # Adds the current trial number to the video\n",
    "            subjectHullCentroidArenaStartOutText=cv2.putText(subjectHullCentroidArenaStartOutText,\n",
    "            '' + str('Trial#: %.0f' % (trialCounter)),\n",
    "            (670,30), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "            \n",
    "            # Adds the current number of collected rewards to the video\n",
    "            subjectHullCentroidArenaStartOutText=cv2.putText(subjectHullCentroidArenaStartOutText,\n",
    "            '' + str('Reward#: %.0f' % (rewardCounter)),\n",
    "            (670,50), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "            \n",
    "            # Writes the modified frame to the video protocol and shows it in a popup window \n",
    "            out.write(subjectHullCentroidArenaStartOutText)\n",
    "            cv2.imshow('Press (q)-to end the experiment',subjectHullCentroidArenaStartOutText)\n",
    "\n",
    "            # Frame ID\n",
    "            frameCounter = frameCounter+1\n",
    "            \n",
    "            # Calculates the percentage of successful/rewarded trials\n",
    "            if (rewardCounter==0):\n",
    "                percentCorrect = 0\n",
    "            else:\n",
    "                percentCorrect = 100/trialCounter*rewardCounter\n",
    "            \n",
    "            # Feede an empty wave to the audio stream\n",
    "            stream.write(silenceSound)\n",
    "            soundPlayed = 'false'\n",
    "            \n",
    "            # Writes a new row to the Excel-protocol\n",
    "            protocolRow = (\n",
    "                    [frameCounter, (time.time()-expTime), expPhase, x, y, startX, startY, startRadius, targetX, targetY, targetRadius, trialCounter, percentCorrect, soundPlayed, commonCycle, target2X, target2Y, target3X, target3Y, target4X, target4Y, target5X, target5Y],\n",
    "                    )\n",
    "            for frame, timeStamp, phase, anX, anY, stX, stY, stRad, tarX, tarY, tarRad, trial, rewP, soundP, comCy, odd1X, odd1Y, odd2X, odd2Y, odd3X, odd3Y, odd4X, odd4Y in (protocolRow):\n",
    "                worksheet.write(row, col,     frame)\n",
    "                worksheet.write(row, col + 1, timeStamp)\n",
    "                worksheet.write(row, col + 2, phase)\n",
    "                worksheet.write(row, col + 3, anX)\n",
    "                worksheet.write(row, col + 4, anY)\n",
    "                worksheet.write(row, col + 5, stX)\n",
    "                worksheet.write(row, col + 6, stY)\n",
    "                worksheet.write(row, col + 7, stRad)\n",
    "                worksheet.write(row, col + 8, tarX)\n",
    "                worksheet.write(row, col + 9, tarY)\n",
    "                worksheet.write(row, col + 10, tarRad)\n",
    "                worksheet.write(row, col + 11, trial)\n",
    "                worksheet.write(row, col + 12, rewP)  \n",
    "                worksheet.write(row, col + 13, soundP)      \n",
    "                worksheet.write(row, col + 14, comCy)       \n",
    "                worksheet.write(row, col + 15, odd1X)  \n",
    "                worksheet.write(row, col + 16, odd1Y)    \n",
    "                worksheet.write(row, col + 17, odd2X)    \n",
    "                worksheet.write(row, col + 18, odd2Y)    \n",
    "                worksheet.write(row, col + 19, odd3X)     \n",
    "                worksheet.write(row, col + 20, odd3Y)    \n",
    "                worksheet.write(row, col + 21, odd4X)  \n",
    "                worksheet.write(row, col + 22, odd4Y)  \n",
    "                row += 1\n",
    "\n",
    "            # Checks, if the subject is in the starting/initialization area\n",
    "            # If so, the protocol proceeds to phase 1 and a timer is started\n",
    "            if (((x-startX)*(x-startX))+((y-startY)*(y-startY))) <= (startRadius*startRadius):\n",
    "                expPhase = 1\n",
    "                startInZone = time.time()\n",
    "            \n",
    "            # If not, the protocol remains in phase 0\n",
    "            else:\n",
    "                expPhase = 0\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break          \n",
    "  \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Phase 1 = Animal is in the starting area\n",
    "    elif expPhase == 1:\n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret==True:\n",
    "\n",
    "            maskedFrame = cv2.bitwise_and(src1 = frame, src2 = mask)\n",
    "                    \n",
    "            ## Animal tracking\n",
    "            # Substracts background from current frame\n",
    "            if backgroundColor == 'T':\n",
    "                subject = cv2.subtract(img,maskedFrame)\n",
    "            else:\n",
    "                subject = cv2.subtract(maskedFrame,img)\n",
    "      \n",
    "            # Converts subject to grey scale\n",
    "            subjectGray = cv2.cvtColor(subject, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Applies blur and thresholding to the subject\n",
    "            kernelSize = (25,25)\n",
    "            frameBlur = cv2.GaussianBlur(subjectGray, kernelSize, 0)\n",
    "            _, thresh = cv2.threshold(frameBlur, 40, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Finds contours and selects the contour with the largest area\n",
    "            ###contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            _, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            \n",
    "            # If there is no subject, the sreen is blackened, indicating that there is a problem\n",
    "            # with the tracking or that your animal has escaped.\n",
    "            # This code block helps when building and testing the setup. During a real experiment,\n",
    "            # the condition hopefully is never met. \n",
    "            if (len(contours) == 0):\n",
    "                x = 20\n",
    "                y = 40\n",
    "                subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "\n",
    "            # If there is a subject, it is tracked\n",
    "            else:\n",
    "                contour = contours[np.argmax(list(map(cv2.contourArea, contours)))]\n",
    "                M = cv2.moments(contour)\n",
    "                if ((M['m00']) == 0):\n",
    "                    x = 20\n",
    "                    y = 40\n",
    "                    subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                    subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "                else:\n",
    "                    x = int(M['m10'] / M['m00'])\n",
    "                    y = int(M['m01'] / M['m00'])\n",
    "                    hull = cv2.convexHull(contour)\n",
    "                    subjectHullCentroid = maskedFrame\n",
    "          \n",
    "            # Draws contour and centroid of the subject\n",
    "            cv2.drawContours(subjectHullCentroid, [contour], 0, BGR_COLOR['green'], 1, cv2.LINE_AA)\n",
    "            subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "            \n",
    "            # Draws the arena contour, the starting platform, and a green dot, signalling that the subject is inside the starting area\n",
    "            subjectHullCentroidArena = cv2.circle(subjectHullCentroid,(arenaX,arenaY), arenaRadius, (0,0,255), 2)\n",
    "            subjectHullCentroidArenaStart = cv2.circle(subjectHullCentroidArena,(startX,startY), startRadius, (255,0,255), 2)\n",
    "            subjectHullCentroidArenaStartIn = cv2.circle(subjectHullCentroidArena,(20,20), 10, BGR_COLOR['green'], -6)\n",
    "            \n",
    "            # Adds a stopwatch for the experiment duration to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartIn,\n",
    "            '' + str('Time: %.2f' % ((time.time()-expTime))),\n",
    "            (10,590), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['white'])   \n",
    "            \n",
    "            # Adds the current trial number to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Trial#: %.0f' % (trialCounter)),\n",
    "            (670,30), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "            \n",
    "            # Adds the current number of collected rewards to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Reward#: %.0f' % (rewardCounter)),\n",
    "            (670,50), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "        \n",
    "            # Writes the modified frame to the video protocol and shows it in a popup window \n",
    "            out.write(subjectHullCentroidArenaStartInText)\n",
    "            cv2.imshow('Press (q)-to end the experiment',subjectHullCentroidArenaStartInText)\n",
    "                        \n",
    "            # Frame ID\n",
    "            frameCounter = frameCounter+1\n",
    "            \n",
    "            # Calculates the percentage of successful/rewarded trials\n",
    "            if (rewardCounter==0):\n",
    "                percentCorrect = 0\n",
    "            else:\n",
    "                percentCorrect = 100/trialCounter*rewardCounter\n",
    "            \n",
    "            ## Checks, if the subject is still in the starting/initialization area \n",
    "            if (((x-startX)*(x-startX))+((y-startY)*(y-startY))) <= (startRadius*startRadius):\n",
    "                stopInZone = time.time()\n",
    "                # Checks, if the time spent in the starting/initialization area exceeds the initiation duration\n",
    "                # If so, the protocol proceeds to phase 2, the trial timer is started, the designated distractor (trial)\n",
    "                # sound is played every \"delayLength\" cycles, and the target areas for the current trial are generated\n",
    "                if (stopInZone-startInZone) >= initDuration:\n",
    "                    expPhase = 2\n",
    "                    startTrial = time.time()\n",
    "                    if (commonCycle == 1):\n",
    "                        stream.write((distractorSoundTrial*ampMod))\n",
    "                        commonCycle = commonCycle+1 \n",
    "                        soundPlayed = 'true-DistractorTrial'\n",
    "                    elif (commonCycle < delayLength and commonCycle >= 2):\n",
    "                        stream.write(silenceSound)\n",
    "                        commonCycle = commonCycle+1\n",
    "                        soundPlayed = 'false'\n",
    "                    elif (commonCycle == delayLength):\n",
    "                        stream.write(silenceSound)\n",
    "                        commonCycle = 1\n",
    "                        soundPlayed = 'false'\n",
    "                    \n",
    "                    # Generates the first target (attractor), which cannot overlap with the starting area\n",
    "                    while ((((randomX-arenaX)*(randomX-arenaX))+((randomY-arenaY)*(randomY-arenaY))) >= (arenaRadius*arenaRadius) or               \n",
    "                               math.sqrt(((startX-randomX)*(startX-randomX))+((startY-randomY)*(startY-randomY))) <= (startRadius+targetRadius)):  \n",
    "\n",
    "                            # random angle\n",
    "                            alpha = 2 * math.pi * random.random()   \n",
    "                            # random radius\n",
    "                            r = (arenaRadius-20-targetRadius) * math.sqrt(random.random())  \n",
    "                            # calculating coordinates\n",
    "                            randomX = int(r * math.cos(alpha) + arenaX)  \n",
    "                            randomY = int(r * math.sin(alpha) + arenaY)  \n",
    "                            targetX = randomX                            \n",
    "                            targetY = randomY                      \n",
    "         \n",
    "                # If the duration spent in the starting area does not exceed the initialization duration, \n",
    "                # the protocol remains in phase 1\n",
    "                else:\n",
    "                    stream.write(silenceSound)\n",
    "                    soundPlayed = 'false'\n",
    "                    commonCycle = 1\n",
    "                    expPhase = 1\n",
    "            \n",
    "            # If the animal leaves the starting area before the initialization duration is reached, \n",
    "            # the protocol goes back to phase 0\n",
    "            else:   \n",
    "                stream.write(silenceSound)\n",
    "                soundPlayed = 'false'\n",
    "                commonCycle = 1\n",
    "                expPhase = 0\n",
    " \n",
    "            # Writes a new row to the Excel-protocol\n",
    "            protocolRow = (\n",
    "                    [frameCounter, (time.time()-expTime), expPhase, x, y, startX, startY, startRadius, targetX, targetY, targetRadius, trialCounter, percentCorrect, soundPlayed, commonCycle, target2X, target2Y, target3X, target3Y, target4X, target4Y, target5X, target5Y],\n",
    "                    )\n",
    "            for frame, timeStamp, phase, anX, anY, stX, stY, stRad, tarX, tarY, tarRad, trial, rewP, soundP, comCy, odd1X, odd1Y, odd2X, odd2Y, odd3X, odd3Y, odd4X, odd4Y in (protocolRow):\n",
    "                worksheet.write(row, col,     frame)\n",
    "                worksheet.write(row, col + 1, timeStamp)\n",
    "                worksheet.write(row, col + 2, phase)\n",
    "                worksheet.write(row, col + 3, anX)\n",
    "                worksheet.write(row, col + 4, anY)\n",
    "                worksheet.write(row, col + 5, stX)\n",
    "                worksheet.write(row, col + 6, stY)\n",
    "                worksheet.write(row, col + 7, stRad)\n",
    "                worksheet.write(row, col + 8, tarX)\n",
    "                worksheet.write(row, col + 9, tarY)\n",
    "                worksheet.write(row, col + 10, tarRad)\n",
    "                worksheet.write(row, col + 11, trial)\n",
    "                worksheet.write(row, col + 12, rewP)    \n",
    "                worksheet.write(row, col + 13, soundP)      \n",
    "                worksheet.write(row, col + 14, comCy)                    \n",
    "                worksheet.write(row, col + 15, odd1X)  \n",
    "                worksheet.write(row, col + 16, odd1Y)    \n",
    "                worksheet.write(row, col + 17, odd2X)    \n",
    "                worksheet.write(row, col + 18, odd2Y)    \n",
    "                worksheet.write(row, col + 19, odd3X)     \n",
    "                worksheet.write(row, col + 20, odd3Y)    \n",
    "                worksheet.write(row, col + 21, odd4X)  \n",
    "                worksheet.write(row, col + 22, odd4Y)     \n",
    "                row += 1    \n",
    "        \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break          \n",
    "  \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    ########################\n",
    "    # Phase 2 = Animal initiated the trial\n",
    "    elif expPhase == 2:\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "\n",
    "            maskedFrame = cv2.bitwise_and(src1 = frame, src2 = mask)\n",
    "            \n",
    "            ## Animal tracking\n",
    "            # Substracts background from current frame\n",
    "            if backgroundColor == 'T':\n",
    "                subject = cv2.subtract(img,maskedFrame)\n",
    "            else:\n",
    "                subject = cv2.subtract(maskedFrame,img)\n",
    "       \n",
    "            # Converts subject to grey scale\n",
    "            subjectGray = cv2.cvtColor(subject, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Applies blur and thresholding to the subject\n",
    "            kernelSize = (25,25)\n",
    "            frameBlur = cv2.GaussianBlur(subjectGray, kernelSize, 0)\n",
    "            _, thresh = cv2.threshold(frameBlur, 40, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Finds contours and selects the contour with the largest area\n",
    "            ###contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            _, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            \n",
    "            # If there is no subject, the sreen is blackened, indicating that there is a problem\n",
    "            # with the tracking or that your animal has escaped.\n",
    "            # This code block helps when building and testing the setup. During a real experiment,\n",
    "            # the condition hopefully is never met. \n",
    "            if (len(contours) == 0):\n",
    "                x = 20\n",
    "                y = 40\n",
    "                subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "\n",
    "            # If there is a subject, it is tracked\n",
    "            else:\n",
    "            \n",
    "                contour = contours[np.argmax(list(map(cv2.contourArea, contours)))]\n",
    "                M = cv2.moments(contour)\n",
    "                if ((M['m00']) == 0):\n",
    "                    x = 20\n",
    "                    y = 40\n",
    "                    subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                    subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "                else:\n",
    "                    x = int(M['m10'] / M['m00'])\n",
    "                    y = int(M['m01'] / M['m00'])\n",
    "                    hull = cv2.convexHull(contour)\n",
    "                    subjectHullCentroid = maskedFrame\n",
    "      \n",
    "            # Draws contour and centroid of the subject\n",
    "            cv2.drawContours(subjectHullCentroid, [contour], 0, BGR_COLOR['green'], 1, cv2.LINE_AA)\n",
    "            subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "            \n",
    "            # Draws the arena contour, the attractor target, and a blue dot, \n",
    "            # signalling that the subject is outside the attractor target area            \n",
    "            subjectHullCentroidArena = cv2.circle(subjectHullCentroid,(arenaX,arenaY), arenaRadius, (0,0,255), 2)\n",
    "            subjectHullCentroidArenaStart = cv2.circle(subjectHullCentroidArena,(targetX,targetY), targetRadius, (0,255,0), 2)\n",
    "            subjectHullCentroidArenaStartIn = cv2.circle(subjectHullCentroidArena,(20,20), 10, BGR_COLOR['blue'], -6)\n",
    "\n",
    "            # Adds a stopwatch for the experiment duration to the video            \n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartIn,\n",
    "            '' + str('Time: %.2f' % ((time.time()-expTime))),\n",
    "            (10,590), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['white'])\n",
    "            \n",
    "            # Adds a trial duration countdown to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Trial: %.2f' % ((trialDuration-trialCountdown))),\n",
    "            (670,590), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['red'])\n",
    "\n",
    "            # Adds the current trial number to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Trial#: %.0f' % (trialCounter)),\n",
    "            (670,30), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "            \n",
    "            # Adds the current number of collected rewards to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Reward#: %.0f' % (rewardCounter)),\n",
    "            (670,50), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "            \n",
    "            # Writes the modified frame to the video protocol and shows it in a popup window \n",
    "            out.write(subjectHullCentroidArenaStartInText)\n",
    "            cv2.imshow('Press (q)-to end the experiment',subjectHullCentroidArenaStartInText)\n",
    "            \n",
    "            # Frame ID\n",
    "            frameCounter = frameCounter+1            \n",
    "            \n",
    "            # Calculates the percentage of successful/rewarded trials\n",
    "            if (rewardCounter==0):\n",
    "                percentCorrect = 0\n",
    "            else:\n",
    "                percentCorrect = 100/trialCounter*rewardCounter\n",
    "\n",
    "            # Current time               \n",
    "            stopTrial = time.time()\n",
    "            \n",
    "            # If the maximum trial duration is reached, the trial is terminated and the protocol goes back to phase 0\n",
    "            if (stopTrial-startTrial) >= trialDuration:\n",
    "                expPhase=0\n",
    "                trialCounter = trialCounter+1\n",
    "                randomX = 9000\n",
    "                randomY = 9000            \n",
    "                random2X = 9000\n",
    "                random2Y = 9000                \n",
    "                random3X = 9000\n",
    "                random3Y = 9000\n",
    "                random4X = 9000\n",
    "                random4Y = 9000\n",
    "                random5X = 9000\n",
    "                random5Y = 9000        \n",
    "                trialCountdown = 0\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # Time left for trial successful trial completion\n",
    "                trialCountdown = (stopTrial-startTrial)\n",
    "                \n",
    "                # Checks, if the animal is in the attractor target area\n",
    "                # If so, acoustic stimulation switches to the designated attractor stimulus and the protocol \n",
    "                # proceeds to phase 3\n",
    "                if (((x-targetX)*(x-targetX))+((y-targetY)*(y-targetY))) <= (targetRadius*targetRadius):\n",
    "                    startInTarget = time.time()\n",
    "                    if (commonCycle == 1):\n",
    "                        stream.write((attractorSoundTarget1*ampMod)) \n",
    "                        commonCycle = commonCycle+1\n",
    "                        stopInTarget = time.time()\n",
    "                        #print((stopInTarget-startInTarget))\n",
    "                        soundPlayed = 'true-AttractorTarget1'\n",
    "                        expPhase = 3\n",
    "                    elif (commonCycle < delayLength and commonCycle >= 2):\n",
    "                        stream.write(silenceSound)\n",
    "                        commonCycle = commonCycle+1\n",
    "                        stopInTarget = time.time()\n",
    "                        #print((stopInTarget-startInTarget))\n",
    "                        soundPlayed = 'false'\n",
    "                        expPhase = 3\n",
    "                    elif (commonCycle == delayLength):\n",
    "                        stream.write(silenceSound)\n",
    "                        commonCycle = 1\n",
    "                        stopInTarget = time.time()\n",
    "                        #print((stopInTarget-startInTarget))\n",
    "                        soundPlayed = 'false'\n",
    "                        expPhase = 3\n",
    "                \n",
    "                # If the animal is not in the target areas, the protocol keeps playing back the designated trial\n",
    "                # distractor stimulus and remains in phase 2\n",
    "                else:\n",
    "                    if (commonCycle == 1):\n",
    "                        stream.write((distractorSoundTrial*ampMod))\n",
    "                        soundPlayed = 'true-DistractorTrial'\n",
    "                        commonCycle = commonCycle+1 \n",
    "                        expPhase = 2\n",
    "                    elif (commonCycle < delayLength and commonCycle >= 2):\n",
    "                        stream.write(silenceSound)\n",
    "                        soundPlayed = 'false'\n",
    "                        commonCycle = commonCycle+1\n",
    "                        expPhase = 2\n",
    "                    elif (commonCycle == delayLength):\n",
    "                        stream.write(silenceSound)\n",
    "                        soundPlayed = 'false'\n",
    "                        commonCycle = 1\n",
    "                        expPhase = 2\n",
    "                            \n",
    "            # Writes a new row to the Excel-protocol        \n",
    "            protocolRow = (\n",
    "                    [frameCounter, (time.time()-expTime), expPhase, x, y, startX, startY, startRadius, targetX, targetY, targetRadius, trialCounter, percentCorrect, soundPlayed, commonCycle, target2X, target2Y, target3X, target3Y, target4X, target4Y, target5X, target5Y],\n",
    "                    )\n",
    "            for frame, timeStamp, phase, anX, anY, stX, stY, stRad, tarX, tarY, tarRad, trial, rewP, soundP, comCy, odd1X, odd1Y, odd2X, odd2Y, odd3X, odd3Y, odd4X, odd4Y in (protocolRow):\n",
    "                worksheet.write(row, col,     frame)\n",
    "                worksheet.write(row, col + 1, timeStamp)\n",
    "                worksheet.write(row, col + 2, phase)\n",
    "                worksheet.write(row, col + 3, anX)\n",
    "                worksheet.write(row, col + 4, anY)\n",
    "                worksheet.write(row, col + 5, stX)\n",
    "                worksheet.write(row, col + 6, stY)\n",
    "                worksheet.write(row, col + 7, stRad)\n",
    "                worksheet.write(row, col + 8, tarX)\n",
    "                worksheet.write(row, col + 9, tarY)\n",
    "                worksheet.write(row, col + 10, tarRad)\n",
    "                worksheet.write(row, col + 11, trial)\n",
    "                worksheet.write(row, col + 12, rewP)\n",
    "                worksheet.write(row, col + 13, soundP)      \n",
    "                worksheet.write(row, col + 14, comCy)      \n",
    "                worksheet.write(row, col + 15, odd1X)  \n",
    "                worksheet.write(row, col + 16, odd1Y)    \n",
    "                worksheet.write(row, col + 17, odd2X)    \n",
    "                worksheet.write(row, col + 18, odd2Y)    \n",
    "                worksheet.write(row, col + 19, odd3X)     \n",
    "                worksheet.write(row, col + 20, odd3Y)    \n",
    "                worksheet.write(row, col + 21, odd4X)  \n",
    "                worksheet.write(row, col + 22, odd4Y)  \n",
    "                row += 1\n",
    "                    \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break     \n",
    "\n",
    "        else:\n",
    "            break       \n",
    "        \n",
    "    # Phase 3 = Animal entered the target area\n",
    "    elif expPhase == 3:\n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "\n",
    "            maskedFrame = cv2.bitwise_and(src1 = frame, src2 = mask)\n",
    "            \n",
    "            ## Animal tracking\n",
    "            # Substracts background from current frame\n",
    "            if backgroundColor == 'T':\n",
    "                subject = cv2.subtract(img,maskedFrame)\n",
    "            else:\n",
    "                subject = cv2.subtract(maskedFrame,img)\n",
    "        \n",
    "            # Converts subject to grey scale\n",
    "            subjectGray = cv2.cvtColor(subject, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Applies blur and thresholding to the subject\n",
    "            kernelSize = (25,25)\n",
    "            frameBlur = cv2.GaussianBlur(subjectGray, kernelSize, 0)\n",
    "            _, thresh = cv2.threshold(frameBlur, 40, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Finds contours and selects the contour with the largest area\n",
    "            ###contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            _, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "          \n",
    "            # If there is no subject, the sreen is blackened, indicating that there is a problem\n",
    "            # with the tracking or that your animal has escaped.\n",
    "            # This code block helps when building and testing the setup. During a real experiment,\n",
    "            # the condition hopefully is never met. \n",
    "            if (len(contours) == 0):\n",
    "                x = 20\n",
    "                y = 40\n",
    "                subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "\n",
    "            # If there is a subject, it is tracked\n",
    "            else:\n",
    "                contour = contours[np.argmax(list(map(cv2.contourArea, contours)))]\n",
    "                M = cv2.moments(contour)\n",
    "                if ((M['m00']) == 0):\n",
    "                    x = 780\n",
    "                    y = 580\n",
    "                    subjectHullCentroid = np.zeros(frame.shape,np.uint8)\n",
    "                    subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "                else:\n",
    "                    x = int(M['m10'] / M['m00'])\n",
    "                    y = int(M['m01'] / M['m00'])\n",
    "                    hull = cv2.convexHull(contour)\n",
    "                    subjectHullCentroid = maskedFrame\n",
    "                \n",
    "          \n",
    "            # Draws contour and centroid of the subject\n",
    "            cv2.drawContours(subjectHullCentroid, [contour], 0, BGR_COLOR['green'], 1, cv2.LINE_AA)\n",
    "            subjectHullCentroid = cv2.circle(subjectHullCentroid, (x,y), 3, BGR_COLOR['yellow'], -1)\n",
    "            \n",
    "            # Draws the arena contour, the attractor target, the distractor target, and a green dot, \n",
    "            # signalling that the subject is inside the attractor target area\n",
    "            subjectHullCentroidArena = cv2.circle(subjectHullCentroid,(arenaX,arenaY), arenaRadius, (0,0,255), 2)\n",
    "            subjectHullCentroidArenaStart = cv2.circle(subjectHullCentroidArena,(targetX,targetY), targetRadius, (0,255,0), 2)\n",
    "            subjectHullCentroidArenaStartIn = cv2.circle(subjectHullCentroidArena,(20,20), 10, BGR_COLOR['green'], -6)\n",
    "      \n",
    "            # Adds a stopwatch for the experiment duration to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartIn,\n",
    "            '' + str('Time: %.2f' % ((time.time()-expTime))),\n",
    "            (10,590), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['white'])\n",
    "            \n",
    "            # Adds a trial duration countdown to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Trial: %.2f' % ((trialDuration-trialCountdown))),\n",
    "            (670,590), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['green'])\n",
    "            \n",
    "            # Adds a target duration countdown to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Target: %.2f' % ((targetDuration-targetCountdown))),\n",
    "            (670,570), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['green'])\n",
    "     \n",
    "            # Adds the current trial number to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Trial#: %.0f' % (trialCounter)),\n",
    "            (670,30), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "            \n",
    "            # Adds the current number of collected rewards to the video\n",
    "            subjectHullCentroidArenaStartInText=cv2.putText(subjectHullCentroidArenaStartInText,\n",
    "            '' + str('Reward#: %.0f' % (rewardCounter)),\n",
    "            (670,50), cv2.FONT_HERSHEY_DUPLEX, .5, BGR_COLOR['blue'])\n",
    "            \n",
    "            # Writes the modified frame to the video protocol and shows it in a popup window \n",
    "            out.write(subjectHullCentroidArenaStartInText)\n",
    "            cv2.imshow('Press (q)-to end the experiment',subjectHullCentroidArenaStartInText)\n",
    "            \n",
    "            # Frame ID\n",
    "            frameCounter = frameCounter+1\n",
    "            \n",
    "            # Calculates the percentage of successful/rewarded trials\n",
    "            if (rewardCounter==0):\n",
    "                percentCorrect = 0\n",
    "            else:\n",
    "                percentCorrect = 100/trialCounter*rewardCounter\n",
    "            \n",
    "            # Checks, if the animal is still in the attractor target area\n",
    "            # If so, acoustic stimulation continues with the designated attractor stimulus and the protocol \n",
    "            # remains in phase 3          \n",
    "            if (((x-targetX)*(x-targetX))+((y-targetY)*(y-targetY))) <= (targetRadius*targetRadius):\n",
    "                \n",
    "                if (commonCycle == 1):\n",
    "                    stream.write((attractorSoundTarget1*ampMod)) \n",
    "                    stopInTarget = time.time()\n",
    "                    soundPlayed = 'true-AttractorTarget1'\n",
    "                    commonCycle = commonCycle+1\n",
    "                    expPhase = 3\n",
    "                elif (commonCycle < delayLength and commonCycle >= 2):\n",
    "                    stream.write(silenceSound)\n",
    "                    stopInTarget = time.time()\n",
    "                    soundPlayed = 'false'\n",
    "                    commonCycle = commonCycle+1\n",
    "                    expPhase = 3\n",
    "                elif (commonCycle == delayLength):\n",
    "                    stream.write(silenceSound)\n",
    "                    stopInTarget = time.time()\n",
    "                    soundPlayed = 'false'\n",
    "                    commonCycle = 1\n",
    "                    expPhase = 3\n",
    "                    \n",
    "                # Checks, if the desired target duration is reached   \n",
    "                # If so, the subject is rewarded, the trial and reward counters are increased by 1,\n",
    "                # the target countdown stops, and the protocol goes back to phase 1\n",
    "                if (stopInTarget-startInTarget) >= targetDuration:\n",
    "                    trialCounter = trialCounter+1\n",
    "                    randomX = 9000\n",
    "                    randomY = 9000\n",
    "                    rewardCounter = rewardCounter+1\n",
    "                    targetCountdown = 0\n",
    "                    \n",
    "                    # Activates the current feeder and switches to the other feeder for the next reward\n",
    "                    if (feederID == 1):\n",
    "                        while True:\n",
    "                            try:\n",
    "                                board.digital[arduinoFeeder1].write(1) \n",
    "                                time.sleep(.068)\n",
    "                                board.digital[arduinoFeeder1].write(0) \n",
    "                                startTrial = time.time()\n",
    "                                feederID = 2\n",
    "                                expPhase = 0\n",
    "                            # This code block helps when building and testing the setup. During a real experiment,\n",
    "                            # the condition hopefully is never met.\n",
    "                            except:\n",
    "                                decision = input(\"Feeder Error: \"\n",
    "                                                 \"Please check the Arduino for problems! \"\n",
    "                                                 \"Try to continue with reward? [Y]: \")\n",
    "                                if decision == 'Y':\n",
    "                                    continue\n",
    "                                elif decision != 'Y':\n",
    "                                    startTrial = time.time()\n",
    "                                    feederID = 2\n",
    "                                    expPhase = 0\n",
    "                                    break\n",
    "                            break\n",
    "                        \n",
    "                    # Activates the current feeder and switches to the other feeder for the next reward   \n",
    "                    elif (feederID == 2):\n",
    "                        while True:\n",
    "                            try:\n",
    "                                board.digital[arduinoFeeder2].write(1) \n",
    "                                time.sleep(.068)\n",
    "                                board.digital[arduinoFeeder2].write(0) \n",
    "                                startTrial = time.time()\n",
    "                                feederID = 1\n",
    "                                expPhase = 0\n",
    "                            # This code block helps when building and testing the setup. During a real experiment,\n",
    "                            # the condition hopefully is never met.\n",
    "                            except:\n",
    "                                decision = input(\"Feeder Error: \"\n",
    "                                                 \"Please check the Arduino for problems! \"\n",
    "                                                 \"Try to continue with reward? [Y]: \")\n",
    "                                if decision == 'Y':\n",
    "                                    continue\n",
    "                                elif decision != 'Y':\n",
    "                                    startTrial = time.time()\n",
    "                                    feederID = 1\n",
    "                                    expPhase = 0\n",
    "                                    break\n",
    "                            break\n",
    "                \n",
    "                # If the desired target duration is not reached, the protocol remains in phase 3 and the\n",
    "                # countdown continues\n",
    "                else:\n",
    "                    expPhase = 3\n",
    "                    targetCountdown = (stopInTarget-startInTarget)\n",
    "\n",
    "            # If the animal has left the attractor target area, the protocol switches to the designated trial\n",
    "            # distractor stimulus and goes back to phase 2\n",
    "            else:\n",
    "                if (commonCycle == 1):\n",
    "                    stream.write((distractorSoundTrial*ampMod))\n",
    "                    soundPlayed = 'true-DistractorTrial'\n",
    "                    commonCycle = commonCycle+1 \n",
    "                    expPhase = 2\n",
    "                elif (commonCycle < delayLength and commonCycle >= 2):\n",
    "                    stream.write(silenceSound)\n",
    "                    soundPlayed = 'false'\n",
    "                    commonCycle = commonCycle+1\n",
    "                    expPhase = 2\n",
    "                elif (commonCycle == delayLength):\n",
    "                    stream.write(silenceSound)\n",
    "                    soundPlayed = 'false'\n",
    "                    commonCycle = 1\n",
    "                    expPhase = 2\n",
    "\n",
    "            # Writes a new row to the Excel-protocol\n",
    "            protocolRow = (\n",
    "                    [frameCounter, (time.time()-expTime), expPhase, x, y, startX, startY, startRadius, targetX, targetY, targetRadius, trialCounter, percentCorrect, soundPlayed, commonCycle, target2X, target2Y, target3X, target3Y, target4X, target4Y, target5X, target5Y],\n",
    "                    )\n",
    "            for frame, timeStamp, phase, anX, anY, stX, stY, stRad, tarX, tarY, tarRad, trial, rewP, soundP, comCy, odd1X, odd1Y, odd2X, odd2Y, odd3X, odd3Y, odd4X, odd4Y in (protocolRow):\n",
    "                worksheet.write(row, col,     frame)\n",
    "                worksheet.write(row, col + 1, timeStamp)\n",
    "                worksheet.write(row, col + 2, phase)\n",
    "                worksheet.write(row, col + 3, anX)\n",
    "                worksheet.write(row, col + 4, anY)\n",
    "                worksheet.write(row, col + 5, stX)\n",
    "                worksheet.write(row, col + 6, stY)\n",
    "                worksheet.write(row, col + 7, stRad)\n",
    "                worksheet.write(row, col + 8, tarX)\n",
    "                worksheet.write(row, col + 9, tarY)\n",
    "                worksheet.write(row, col + 10, tarRad)\n",
    "                worksheet.write(row, col + 11, trial)\n",
    "                worksheet.write(row, col + 12, rewP)\n",
    "                worksheet.write(row, col + 13, soundP)      \n",
    "                worksheet.write(row, col + 14, comCy)                       \n",
    "                worksheet.write(row, col + 15, odd1X)  \n",
    "                worksheet.write(row, col + 16, odd1Y)    \n",
    "                worksheet.write(row, col + 17, odd2X)    \n",
    "                worksheet.write(row, col + 18, odd2Y)    \n",
    "                worksheet.write(row, col + 19, odd3X)     \n",
    "                worksheet.write(row, col + 20, odd3Y)    \n",
    "                worksheet.write(row, col + 21, odd4X)  \n",
    "                worksheet.write(row, col + 22, odd4Y)  \n",
    "                row += 1\n",
    "                \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break          \n",
    "  \n",
    "        else:\n",
    "            break\n",
    "\n",
    "# If the session is over or interrupted, all capture and output devices are released, streams are stopped, \n",
    "# windows are destroyed, Excel-files are saved, and the communication with the Arduino is terminated\n",
    "cap.release()\n",
    "out.release()\n",
    "stream.stop()\n",
    "cv2.destroyAllWindows()\n",
    "workbook.close()\n",
    "board.exit()                              \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
